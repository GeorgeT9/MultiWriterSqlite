# Мультипоточная обработка текста

### Пример использования node.js для обработки текстовой информации, хранимой в файлах, с последующей мультипоточной записью результатов в файлы sqlite

При использовании СУБД Sqlite3 приходится сталкиваться с проблемой производительности при необходимости выполнять операции переиндексации после каждой массовой вставки данных. Так, при каждой сессией на вставку данных необходимо выполнить удаление индексов, а
после вставки их построение. Это начинает занимать ощутимое время при достижении размера данных в несколько Гб. Поскольку в СУБД Sqlite нет встроенного механизма партиций, а сама БД реализована в виде отдельного файла, представляется использовать несколько отдельных файлов БД для уменьшения размера данных для индексации, а также осуществления многопоточной записи.

!!! В настоящее время реализован только механизм записи новых данных (сравнение с уже записанными данными не производится, что будет приводить к дублированию и ошибкам ограничения целостности СУБД при повторной записи уже сохраненных файлов) 

**Файл конфигурации config.json содержит следующие поля:**
*"watchDir"* - каталог в котором находятся файлы для обработки;
*"storeDir"* - каталог, где будут сформированы результирующие файлы sqlite (должен существовать);
*"limitPartMb"* - лимит на размер файлов, записанных в один файл sqlite 
    (лимит сравнивается только в начале сессии обработки, т.е. если в момент начала обработки 
    сумма размеров файлов в файле sqlite не превышает указанный лимит, то запись будет 
    осуществляться в него в рамках всей сессии)
*"countWorkers"* - количество потоков, используемых для обработки;
*"onlyThisExts"* - расширение обрабатываемых файлов.

    Метод process объекта класса Dispatcher возвращает промис, который разрешается при выполнении 
обработки заданного каталога. В данном методе формируется заданное количество инстансов 
*node:worker_thread* каждый из которых представляет соединение с отдельным экземпляром sqlite
через инстанс класса PartConnect. Для формализации уведомлений от воркеров 
используется интерфейс (тип) WorkerNotification. Роль очереди задач выполняет асинхронный итератор (полученный от асинхронного генератора genFileNamesFromDir). При исчерпании очереди в каждый воркер
отправляется значение null, которое интерпретируется как команда на закрытие.
    В воркере обработка файла выполняется методом PartConnect#processFile, в котором для каждого
файла выполняется построение pipeline, объединяющего потоки: 
    ReadSream - формируется в зависимости от расширения файла с помощью функции getTextExtractorFromFile,
    Transform - TextBlockStream - выравнивает блоки текста по окончанию строки,
    Transform - HandlerTransformerStream - выполняет обработку текста и преобразование его в объекты TextBox,
    WriteStream - инстанс класса FilePartWriter, выполняющий запись в БД всего файла одной транзакцией.

    Каждое новое соединение с файлом БД инициализируется инструкциями sql из файла
*/sql/part.sql*, в рамках которых создается внутреннее представление, необходимое для выполнения 
полнотекстового поиска. При закрытии соединения выполняется построение индекса над Items. При переиспользовании существующего соединения данный индекс удаляется (при выполнении записи). 




